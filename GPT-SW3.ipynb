{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-SW3\n",
    "Info: https://huggingface.co/docs/transformers/main/en/model_doc/gpt-sw3 OCH https://www.ai.se/en/node/81535/gpt-sw3  \n",
    "  \n",
    "Fick inbjudan genom att anmäla mig via denna länk: https://docs.google.com/forms/d/e/1FAIpQLSebZv__Me6YUO_kFetDZevwXgSsYSVnXWzG5H68MIwN4XmdtQ/viewform\n",
    "\n",
    "Borde inte ta långt innan man får mejl, men hör av om det tar för lång tid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233cb5731e224b998b8e74c328a170f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login  \n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Initialize Variables\n",
    "model_name = \"AI-Sweden-Models/gpt-sw3-126m\" #Model name\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" #Use GPU if available\n",
    "prompt = \"Träd är fina för att\"\n",
    "\n",
    "# Initialize Tokenizer & Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Träd är fina för att man kan göra många fina saker, men det är ju så att man måste variera sig. Man vet aldrig!\n",
      "\n",
      "Nu är det så här att jag är ingen van datoranvändare, så jag har inte riktigt hunnit med att blogga så mycket. Men det är ju kul!\n",
      "\n",
      "Det här är mitt nya hem, och jag är så glad! Jag har en liten dotter som är 11 månader, och hon är en så söt liten tjej! Hon har fått en storasyster! Hon bor\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "generated_token_ids = model.generate(\n",
    "    inputs = input_ids,\n",
    "    max_new_tokens = 100,\n",
    "    do_sample = True,\n",
    "    temperature = 0.6,\n",
    "    top_p = 1,\n",
    ")[0]\n",
    "\n",
    "generated_text = tokenizer.decode(generated_token_ids)    \n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
